{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 30894,
     "databundleVersionId": 3147400,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30664,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Assuming crypto_df is your DataFrame loaded with cryptocurrency data\n",
    "# Ensure 'Close' and 'log_return' columns are present and calculated\n"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data_folder = \"../input/g-research-crypto-forecasting/\"\n",
    "!ls $data_folder"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "crypto_df = pd.read_csv(data_folder + 'train.csv')"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "crypto_df.head(10)"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "asset_details = pd.read_csv(data_folder + 'asset_details.csv')\n",
    "asset_details"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Select the most recent 8% of the data for training\n",
    "crypto_df = crypto_df.tail(int(len(crypto_df) * 0.08))"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Convert timestamp to datetime for easier handling\n",
    "crypto_df['datetime'] = pd.to_datetime(crypto_df['timestamp'], unit='s')\n",
    "\n",
    "# Feature Engineering: Calculate log returns\n",
    "crypto_df['log_return'] = np.log(crypto_df['Close'] / crypto_df['Close'].shift(1))\n",
    "\n",
    "# Calculate additional features: moving averages\n",
    "crypto_df['ma7'] = crypto_df['Close'].rolling(window=7).mean()\n",
    "crypto_df['ma21'] = crypto_df['Close'].rolling(window=21).mean()"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Drop rows with NaN values resulting from feature engineering\n",
    "crypto_df.dropna(inplace=True)"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def create_sequences(data, sequence_length):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for i in range(len(data)-sequence_length-1):\n",
    "        x = data[i:(i+sequence_length)]\n",
    "        y = data[i+sequence_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# Selecting close prices and log returns as features\n",
    "data = crypto_df[['Close', 'log_return']].values\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Create sequences\n",
    "sequence_length = 5  # Use the past 60 timesteps to predict the next timestep\n",
    "X, y = create_sequences(data_scaled, sequence_length)\n"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(2))  # Predicting Close price and log return simultaneously\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "history = model.fit(X_train, y_train, epochs=6, batch_size=8, validation_split=0.1, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "# Save the entire model to a HDF5 file.\n",
    "model.save('my_model.h5')"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Evaluate the model on the test set\n",
    "test_performance = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f'Test Loss: {test_performance}')\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Visualize the prediction\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(y_test[:, 0], label='Actual')\n",
    "plt.plot(y_pred[:, 0], label='Predicted')\n",
    "plt.title('Prediction of Close Price')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Normalized Close Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluate the model with MAE and RMSE\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# Calculate MAE and RMSE using the true labels (y_test) and the predictions (y_pred)\n",
    "mae = mean_absolute_error(y_test[:, 0], y_pred[:, 0])\n",
    "rmse = sqrt(mean_squared_error(y_test[:, 0], y_pred[:, 0]))\n",
    "\n",
    "# Print the evaluation results\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
